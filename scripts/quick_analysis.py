"""
Quick Analysis Script for Amazon Sentiment Analysis Project

This script provides a quick overview of the key findings from the analysis.
"""

import pandas as pd
import json
import sys
import os

# Add src directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from analysis.sentiment_analyzer import SentimentAnalyzer


def load_processed_data():
    """Load processed data files."""
    try:
        # Load processed data
        df_cleaned = pd.read_parquet('data/processed/data_cleaned.parquet')
        df_cross = pd.read_parquet('data/processed/data_cross_sectional.parquet')
        
        print(f"âœ… Loaded cleaned data: {len(df_cleaned):,} reviews")
        print(f"âœ… Loaded cross-sectional data: {len(df_cross):,} users")
        
        return df_cleaned, df_cross
    
    except FileNotFoundError as e:
        print(f"âŒ Data file not found: {e}")
        print("Please ensure processed data files are in the correct location.")
        return None, None


def load_analysis_results():
    """Load analysis results from JSON files."""
    results = {}
    
    result_files = {
        'sentiment_validation': 'data/results/sentiment_validation.json',
        'statistical_modeling': 'data/results/statistical_modeling.json',
        'clustering_results': 'data/results/clustering_results.json'
    }
    
    for key, filepath in result_files.items():
        try:
            with open(filepath, 'r') as f:
                results[key] = json.load(f)
            print(f"âœ… Loaded {key} results")
        except FileNotFoundError:
            print(f"âš ï¸  {key} results not found")
            results[key] = None
    
    return results


def display_key_findings(df_cleaned, df_cross, results):
    """Display key findings from the analysis."""
    print("\n" + "="*60)
    print("ğŸ¯ AMAZON BEAUTY REVIEWS SENTIMENT ANALYSIS - KEY FINDINGS")
    print("="*60)
    
    # Data Overview
    print("\nğŸ“Š DATA OVERVIEW")
    print("-" * 30)
    print(f"Total Reviews: {len(df_cleaned):,}")
    print(f"Total Users: {len(df_cross):,}")
    print(f"Date Range: {df_cleaned['timestamp'].min()} to {df_cleaned['timestamp'].max()}")
    
    # Sentiment Distribution
    print("\nğŸ’­ SENTIMENT DISTRIBUTION")
    print("-" * 30)
    analyzer = SentimentAnalyzer()
    sentiment_summary = analyzer.get_sentiment_summary(df_cleaned)
    
    print(f"Mean Sentiment: {sentiment_summary['basic_stats']['mean_sentiment']:.3f}")
    print(f"Sentiment Range: [{sentiment_summary['basic_stats']['min_sentiment']:.3f}, {sentiment_summary['basic_stats']['max_sentiment']:.3f}]")
    print("\nSentiment Categories:")
    for category, percentage in sentiment_summary['percentages'].items():
        print(f"  {category.capitalize()}: {percentage:.1f}%")
    
    # Rating Distribution
    print("\nâ­ RATING DISTRIBUTION")
    print("-" * 30)
    rating_dist = df_cleaned['rating'].value_counts().sort_index()
    for rating, count in rating_dist.items():
        percentage = (count / len(df_cleaned)) * 100
        print(f"  {rating} stars: {count:,} ({percentage:.1f}%)")
    
    # Key Correlations
    print("\nğŸ”— KEY CORRELATIONS")
    print("-" * 30)
    
    # Calculate overall correlation
    overall_corr = analyzer.manual_correlation(
        df_cleaned['sentiment'].tolist(),
        df_cleaned['rating'].tolist()
    )
    print(f"Overall Sentiment-Rating Correlation: {overall_corr:.4f}")
    
    # User type analysis
    single_users = df_cleaned[df_cleaned['user_type'] == 'single']
    multi_users = df_cleaned[df_cleaned['user_type'] == 'multi']
    
    if len(single_users) > 0:
        single_corr = analyzer.manual_correlation(
            single_users['sentiment'].tolist(),
            single_users['rating'].tolist()
        )
        print(f"Single-review Users Correlation: {single_corr:.4f}")
    
    if len(multi_users) > 0:
        multi_corr = analyzer.manual_correlation(
            multi_users['sentiment'].tolist(),
            multi_users['rating'].tolist()
        )
        print(f"Multi-review Users Correlation: {multi_corr:.4f}")
    
    # Model Performance
    if results['statistical_modeling']:
        print("\nğŸ“ˆ MODEL PERFORMANCE")
        print("-" * 30)
        model_results = results['statistical_modeling']
        
        if 'model2_sentiment_to_rating' in model_results:
            model2 = model_results['model2_sentiment_to_rating']
            print(f"Sentiment â†’ Rating Model:")
            print(f"  Coefficient: {model2['slope']:.4f}")
            print(f"  R-squared: {model2['r_squared']:.4f}")
        
        if 'model1_sentiment_change_to_rating_change' in model_results:
            model1 = model_results['model1_sentiment_change_to_rating_change']
            print(f"Sentiment Change â†’ Rating Change Model:")
            print(f"  Coefficient: {model1['slope']:.4f}")
            print(f"  R-squared: {model1['r_squared']:.4f}")
    
    # User Segmentation
    print("\nğŸ‘¥ USER SEGMENTATION")
    print("-" * 30)
    user_type_dist = df_cross['user_type'].value_counts()
    for user_type, count in user_type_dist.items():
        percentage = (count / len(df_cross)) * 100
        print(f"  {user_type.capitalize()}-review users: {count:,} ({percentage:.1f}%)")
    
    # Clustering Results
    if results['clustering_results'] and 'cluster_statistics' in results['clustering_results']:
        print("\nğŸ¯ USER CLUSTERS")
        print("-" * 30)
        clusters = results['clustering_results']['cluster_statistics']
        cluster_names = results['clustering_results'].get('cluster_names', {})
        
        for cluster_id, stats in clusters.items():
            name = cluster_names.get(int(cluster_id), f"Cluster {cluster_id}")
            print(f"  {name}: {stats['count']} users")
            print(f"    Avg Sentiment: {stats['avg_sentiment']:.3f}")
            print(f"    Avg Rating: {stats['avg_rating']:.3f}")
    
    # Business Insights
    print("\nğŸ’¡ BUSINESS INSIGHTS")
    print("-" * 30)
    print("â€¢ Strong sentiment-rating correlation validates sentiment analysis effectiveness")
    print("â€¢ User segmentation reveals distinct behavioral patterns")
    print("â€¢ Predictive models show large effect sizes (RÂ² > 0.25)")
    print("â€¢ Multi-review users show slightly higher correlations")
    print("â€¢ Sentiment analysis can effectively predict rating behavior")
    
    print("\n" + "="*60)
    print("Analysis completed successfully! ğŸ‰")
    print("="*60)


def main():
    """Main function to run quick analysis."""
    print("ğŸš€ Starting Amazon Sentiment Analysis Quick Overview...")
    
    # Load data
    df_cleaned, df_cross = load_processed_data()
    
    if df_cleaned is None or df_cross is None:
        print("âŒ Cannot proceed without data files.")
        return
    
    # Load results
    results = load_analysis_results()
    
    # Display findings
    display_key_findings(df_cleaned, df_cross, results)
    
    print("\nğŸ“ For detailed analysis, check:")
    print("  â€¢ results/figures/ - Interactive visualizations")
    print("  â€¢ data/results/ - Detailed JSON results")
    print("  â€¢ docs/ - Methodology and documentation")


if __name__ == "__main__":
    main()
